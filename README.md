# Практическая работа №2

## Описание компонентов

### Классы и их назначение

-   **producer.py**: Продюсер, который создает сообщения и отправляет их в топик `messages-topic`.
    -   Использует сериализацию в формат JSON.
    -   Настроен на гарантию доставки "At Least Once" (`acks='all'`) и имеет 5 попыток повторной отправки (`retries=5`).
    -   Выводит в консоль каждое отправляемое сообщение.

-   **single_consumer.py**: Консьюмер, который считывает сообщения по одному.
    -   Принадлежит к группе `single-message-group`.
    -   Использует автоматический коммит оффсетов (`enable_auto_commit=True`).
    -   Десериализует сообщения из JSON и выводит их в консоль.

-   **batch_consumer.py**: Консьюмер, который считывает сообщения пачками (до 10 за раз).
    -   Принадлежит к группе `batch-message-group`.
    -   Использует ручное управление оффсетами (`enable_auto_commit=False`). Коммит происходит после обработки всей пачки.
    -   Настроен на ожидание данных, чтобы формировать пачки (`fetch_min_bytes`, `fetch_max_wait_ms`).

### Принцип работы приложения

1.  Продюсер генерирует 20 сообщений и отправляет их в Kafka.
2.  Оба консьюмера подписаны на один и тот же топик, но так как у них разные `group_id`, они оба получат все 20 сообщений.
3.  `SingleMessageConsumer` будет получать и обрабатывать сообщения по одному, подтверждая получение автоматически.
4.  `BatchMessageConsumer` будет накапливать сообщения и обрабатывать их пачками, подтверждая получение вручную после обработки всей пачки.

## Инструкция по запуску и проверке
### Шаг 1: Установка зависимостей
Убедитесь, что у вас установлен Python 3 и Docker. Установите необходимую библиотеку:
```bash
pip install kafka-python

### Шаг 2: Запуск Kafka-кластера
Сохраните код из секции "Шаг 1" в файл docker-compose.yml.
В терминале, в папке с файлом, выполните команду:
bash
docker-compose up -d
Проверьте, что все контейнеры запущены:
bash
docker-compose ps
### Шаг 3: Создание топика
Выполните в терминале команду для создания топика (она есть в файле topic.txt):

bash
docker exec -it kafka1 kafka-topics --create --topic messages-topic --partitions 3 --replication-factor 2 --bootstrap-server kafka1:29092
### Шаг 4: Запуск приложения
Для проверки параллельной работы откройте три разных окна терминала.

В первом терминале запустите консьюмер, который читает по одному сообщению:
bash
python single_consumer.py
Во втором терминале запустите консьюмер, который читает пачками:
bash
python batch_consumer.py
В третьем терминале запустите продюсер для отправки сообщений:
bash
python producer.py
### Шаг 5: Проверка результата
В терминале с продюсером вы увидите логи об отправке 20 сообщений.
В терминале с single_consumer.py вы увидите, как сообщения появляются и обрабатываются по одному.
В терминале с batch_consumer.py вы увидите, как сообщения появляются пачками.
Откройте Kafka UI в браузере по адресу http://localhost:8080. Выберите ваш кластер, перейдите в раздел "Topics" -> "messages-topic" -> "Consumers". Вы увидите две группы консьюмеров (single-message-group и batch-message-group) и сможете отслеживать их оффсеты.
